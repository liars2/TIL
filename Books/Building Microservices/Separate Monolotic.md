모노리식 서비스 분리하기
=========================

    모놀로식은 마이크로서비스와 달리 강한 결합성, 낮은 응집력을 가지고 있는건 잘 알고 있다.
    근데, 왜? 꼭 모놀리식을 마이크로서비스로 바꿔야 하는가?

모놀리식 서비스를 마이크로서비스로 바꾸었을 때의 장점
-----------------------------------------------------

1. 변경의 속도
    - 배포하는데 속도 제한이 걸리지 않는다.
2. 팀 분활
    - 한가지 모놀리식 서비스의 개발이 아닌 마이크로서비스 단위로 개발을 할 수 있다.
3. 기술의 이기종성
    - 한가지 언어로 구현되있는게 아닌 서비스에 맞는 언어를 선택해서 구현할 수 있다! (서비스 지향 아키텍쳐)
4. DB 분리
    - 이후 밑에서 다룰 예정이다.
5. 보안
    - 각 각의 서비스 마다 접근 할 수 있는 리소스가 다르니, 보안적 측면에서도 좋다.

> 사용하고 있는 비지니스에 위 장점들이 **필요하다고 판단한다면,** 마이크로서비스로 바꾸는것이 더 효율적이다.

모놀리식 서비스의 접합부
---------------------------

보통 접합부라고 생각을 한다면 코드베이스에서 각각의 서비스를 잇는 부분이라고 생각할 수 있는데

모놀리식 서비스의 접합부는 이 접합부를 지워도 나머지 모놀리식 서비스에서는 영향이 없는 부분이다.

> 그럼 가장 좋은 접합부를 추상적인 개념으로 묶는다면 어떤 기준이 좋을까?

앞서 배운 BC(Bounded Context)가 좋은 접합부라고 볼 수 있다. 아예 경계선으로 나눈 도메인들의 집합이니까.

공예
---------

모놀리식은 대리석 공예로 비교해도 손색없을 정도로 공예를 하면서 지켜야 할 원칙들이 비슷하다

목적을 비유해보면 이와 같이 성립할 수 있다.

> 큰 대리석(모놀리식)을 깍아서(분리) 조각상(마이크로서비스)로 만드는 것이니까.

또 이런 원칙도 같다.

> 한 번에 모든것을 깍으려고 하지 않고 (Big Bang, 점진적 접근법)
> 머리, 몸통, 다리 한 부위마다 (DB Schema, Packaging..)
> 하나씩 차근 차근 (CodeBase 수정 -> DB Separate..)

모놀리식 분리순서
=====================

    모놀리식 서비스를 마이크로서비스로 바꾸는 단위를 나누자면,
    코드베이스와 데이터베이스로 분리 순서가 나뉘어 진다.

코드베이스
----------

1. 콘텍스트 대표하는 패키지를 구성한다

2. 대표 패키지로 **접합부를 기준으로 한** 기존 코드를 이동시킨다.

3. 코드 이동 도중에 발생하는 의존성을 분석한 후 대응한다.

데이터베이스
----------

1. 데이터베이스에 읽고 쓰는 코드 부분을 나눔

2. 객체 혹은 데이터 구조를 매핑하기 쉽게 분활 분할

3. 데이터베이스 리팩토링

데이터베이스 분할 작업중 발생하는 문제점들
------------------------------------------

### 외부 키 관계

    외래키로 다른 DB를 접근한다면, 이 서비스는 어떻게 바꿀 수 있을까?

1. 외래키로 접근하는 해당 코드를 지운다.
2. 해당 정보를 가져올 수 있는 API를 만든다.

이렇게 API를 사용하여 서로 분리된 DB와 네트워크 호출로 데이터를 처리한다면, 우리가 원하는 느슨한 결합성을 기대할 수 있다.

### 공유 정적 데이터

    어떤 정적 테이블을(ex. 국가코드) 모든 서비스가 공유하여 높은 결합성을 초래하는 경우가 있다.
    그런 테이블은 다음과 같은 방법으로 분해를 한다.

1. Ctrl C+V
    - 정적 테이블을 사용하는 서비스 마다 따로 복제하여 붙여넣는다.
    </br>만약 테이블 중 하나에 데이터가 추가된다면 나머지 테이블도 추가하여야 하는 번거로움과 위험성(잊고 추가를 안했을 시에)이 일어난다.

2. 열거형 데이터화
    - 자바에서 사용하는 Enum 처럼, 코드에서 공유할 수 있는 정적 데이터로 존재하는 것이다.
    </br>데이터 테이블로 구현하는 것 보다는 쉬운 방법이지만, 데이터 일관성의 문제가 초래한다.

3. 공유 정적 데이터 서비스
    - 극단적으로, 데이터를 반환하는 서비스로 만드는 것이다.

### 공유 데이터
    재무 서비스와(결제, 환불 등등) 창고 서비스가(제품 발송, 수신) 있는데
    재무는 고객 테이블에 대한 접근을 하고 창고 서비스도 고객 테이블에 대한 접근을 한다고 했을 때
    고객는 분리되지 않는 데이터로 강한 결합성을 나타낸다.

도메인 개념으로 봤을 때, 고객 테이블은 고객 도메인으로 바꿀 수 있다.

고객 서비스로 만든 뒤 재무와 창고 서비스가 이용할 수 있도록 API를 만들면 우리가 원하는 느슨한 결합성으로 이루어진 서비스가 될 수 있다.

데이터 베이스 리팩토링
----------------------

    앞서 설명한 내용은 데이터 베이스를 분리할 때 발생하는 문제점이였다.
    이제 실제로 분리하는 방법에 대해 다루어 보자

### 단계적인 분리

    코드 베이스도 단계별로 분류를 하였는데, 데이터 베이스도 마찬가지로 단계별로 분류를 한다.

1. 스키마 분류
    - 각각의 애플리케이션으로 만들기 전에 서비스는 이전과 같이 하나로 유지한 채 스키마를 분류한다.

2. 애플리케이션을 서비스로 분리

하지만, 이렇게 스키마를 나눈 후 애플리케이션 코드를 나눌때 우리는 **트랜잭션에** 대해서 많은 고려를 해야한다.

트랜잭션의 경계
----------------

    트랜잭션을 보장하기 위해 트랜잭션의 경계를 설정해야하는데
    이 트랜잭션에 대해서 알아야 왜 트랜잭션을 사용해야 하는지 알아야만 한다.

### 트랜잭션

    우리가 ATM에서 돈을 뽑는다고 가정을 해보자.

먼저, ATM에서 출금 메뉴를 누르고 카드를 넣고 원하는 인출금액을 선택하고 돈과 카드를 가지고 나가면 된다.

그런데 만약에 인출 금액을 선택하고 인출하는 과정에서 *모종의 전산 오류로 돈은 나오지 않은채 거래 종료가 된다면?*

**고객 DB에는 정상적으로 돈이 인출됬다 판단하여 계좌 금액에서는 그 인출금액이 통장에서 빠져나갈 것이다.**

이 사태를 막기 위해 만들어진 것이 트랜잭션이다.

이벤트가 모두 발생하거나 전혀 발생하지 않게 해주는 것으로, 데이터베이스에 데이터를 입력할 때 매우 유용하며

잘못된 경우에는 모든 것을 롤백하여 데이터의 불일치 상태를 피할 수 있기 때문이다.

### 마이크로서비스의 트랜잭션 구현

    모놀리식 서비스는 스키마가 하나라, 모든 생성과 업데이트는 단일 트랜잭션 경계 내에서 수행되어 안정성 있지만
    분리되어 동작하는 마이크로서비스 같은 경우에는 서로 다른 스키마를 사용하여 트랜잭션의 안정성을 잃게되는데 트랜잭션을 보장 할 수 있는 방법이 있을까?

각각의 스키마에 접근하는 것에 트랜젝션을 걸었다고 가정해도 이와같은 상황이 발생할 수 있다.

> ATM에서 돈이 정상적으로 출금이 됬음 (성공한 이벤트)
> 모종의 전산 오류로 사용자의 정보에서 출금 이벤트가 발생하지 않아 돈이 그대로 남음 (실패한 이벤트)

이런 상황을 피할 수 있도록 몇 가지 방법이 존재한다

#### 나중에 재시도 하기

    출금이 됬다는 이벤트를 모아두어 재시도하기에 충분하다
    그래서 이런 연산을 큐나 혹은 로그파일에 큐잉하여 나중에 재시도 해도 된다.

[이것은 최종적 일관성의 또 다른 형태다.](https://en.wikipedia.org/wiki/Consistency_model)

**이런 접근 방식은 비즈니스 작업들이 오래 지속될 경우 특히 유용하다.**

#### 전체 작업 중지하기

    다른방안은 전체 작업을 중지하는 것이다.
    이런 경우 시스템을 다시 일관성이 유지된 상태로 복귀시켜야 한다.

보상 트랜잭션을 발행하여, 직전의 트랜젝션을 되돌릴 새로운 트랜잭션을 발생시키는 것이다.

사용자의 계좌정보에서 돈을 빼낼 수도 있고, 여러가지 방법으로 되돌린다면

작업이 실패한 이유와, 같은 작업으로 실패되지 안도록 기록하기 위해 **작업이 실패했다는 UI를 통해 리포트할 필요가 있다.**

여기서 몇 가지 떠오르는 질문이 있다. 이 보상 트랜잭션을 처리하는 로직의 위치는 어디이고, 이 보상 트랜잭션 또한 **실패한다면?**

보상 트랜잭션이 실패한다면, 보상 트랜잭션을 재시도하거나 백엔드 프로세스를 수행할 필요가 있다.

그런데, 이런 일관성이 유지되기 바라는 작업이 한두 개가 아니라 셋, 넷, 다섯... 생각만해도 끔찍하다.

각각의 실패 모드에 대해 보상 트랜잭션을 처리하는 것은 구현은 고사하고 이해하기도 어렵다.

#### 분산 트랜잭션

    보상 트랜잭션을 수동으로 통제하는 방식의 대안은 분산 트랜잭션의 사용이다.
    분산 트랜잭션은 하부 시스템에서 수행되는 다양한 트랜잭션을 통제하기 위해
    트랜잭션 관리자라는 전체적인 통제 프로세스를 사용해 트랜잭션 내부의 여러 트랜잭션을 확장하려고 시도함

분산 트랜잭션은 2단계 커밋을 사용하는데 구조로 표현하면 이렇게 표현할 수 있다.

```
Coordinator                             Cohort
                QUERY TO COMMIT
                --------------->
                  VOTE YES/NO           prepare*/abort*
                <---------------
commit*/abort*    COMMIT/ROLLBACK
                --------------->
                  ACKNOWLEDGMENT        commit*/abort*
                <---------------
end
```

이 단계에서 참여자(Cohort)는 로컬 트랜잭션의 진행 가능 여부를 트랜잭션 매니저에게 알린다.

만약 트랜잭션 매니저가 모든 참여자로부터 찬성표를 얻는다면 참여자에게 각자의 커밋을 수행하라고 지시한다.

**트랜잭션 매니저가 반대표를 하나라도 받는다면 모든 참여자에게 롤백 명령을 보낸다.**

##### 단점

1. 트랜잭션 매니저가 다운된다면?
    - 트랜잭션들은 대기 상태가 되면서 아무것도 못한다.

2. 조정과정은 lock을 의미한다
    - 자원을 잠금 상태로 유지하여, 분산 시스템에서의 확장과 자원 확보의 경쟁에 어려움을 격는다.

### 영영 완벽한 해결책을 찾을 수는 없는가?

    앞서 말한 기능들은 복잡성을 증가시키고, 분산 트랜잭션을 제대로 수행하는 것은 쉽지않으며 실제로 확장성을 저해할 수 있다.
    재시도 보상 로직을 최종 방법으로 사용하는 시스템들은 추론하기 더 어려우며 데이터의 불일치를 고치기 위해 다른 보상 행위가 필요할 수 있다.

정말로 일관성이 유지되어야 하는 상태가 필요하면, 그 상태가 유지되도록 **할 수 있는 모든 것을 노력하여 해야한다.**

불가피하게 분리를 감수해야 한다면 단지 그 과정의 기술적 관점에서 벗어나 트랜잭션 자체를 표현할 구체적인 개념을 만들어라

예를들어, ATM 인출부터 은행 자산 관리 까지 하는 로직을 한데 모으기 적합한 'ATM 인출후 은행 자산 관리'와 같은 개념을 만들 수 있다.

리포팅
----------

    특정 서비스를 더 작은 부분으로 분리하는 데 있어 데이터의 저장 방법과 장소를 잠재적으로 분리할 필요가 있다.

하지만, 이는 **필수적인 사용 사례인 리포팅에 문제가 된다.**

### 리포팅

    마이크로서비스 아키텍쳐로 바꾸는 것과 같은 근본적인 아키텍쳐 변경은 엄청난 혼란을 초래할 수 있지만,
    우리가 하는 모든 것을 포기해야 하는 것을 의미하지는 않는다.

기존 프로세스와 협업 방식을 정할 때, 리포팅 시스템을 이용하며
리포팅 시스템을 이용하는 대상은 평범한 사용자고, 우리는 그들의 요구를 고려해야 한다.

#### 리포팅 데이터베이스

    일반적인 모놀리식 시스템에서는 모든 데이터들은 거대한 단일 데이터베이스에 저장된다.
    모든 데이터를 한 곳에서 모여있어 경계를 넘어 리포팅하는 것이 매우 쉽다.

하지만, 우리는 실제 사용하고 있는 데이터베이스 서버를 리포팅 질의에 의해 성능에 영향을 주는 것을 우려하여 메인 데이터베이스에 실행하지 않을 것이다.

##### 단점

1. 리포팅 데이터베이스는 스키마를 변경하고 조율할 기회를 줄이는 다른 방해물이다.
    - 모놀리식 서비스와 데이터베이스 스키마는 서로 공유하는 API 인데, 마이크로서비스화 하는 작업이 까다롭고 용이하지 못하다.

2. 실제 시스템 또는 리포팅 시스템을 지원하는 사용 사례를 위해 데이터베이스를 최적화하는 방법이 제한적이다.
    - 일부 DB는 읽기용 복제 DB를 최적화하여 효율적인 리포팅을 가능하게 하지만, 데이터 구조 변경이 실행 중인 시스템에 악영향을 주더라도 리포팅을 더 빠르게 하기 위해 데이터를 다르게 구성할 수는 없다.

3. 사용할 수 있는 데이터베이스 종류가 많아져도, 관계형 데이터베이스가 많은 리포팅 도구와 호환되는 SQL 질의 인터페이스를 제공하더라도 동작중인 서비스에 데이터를 저장하기 위한 최선의 방법은 아니다.
    - 문서 지향을 위해 MongoDB를, 대용량 확장이 매우 용의한 Cassandra를.. 이것 저것 사용하고 싶다면 리포팅 시스템을 구축하기는 매우 힘들 것이다.

> 그렇지만, 대부분 리포팅 서비스를 구축하여 운영한다. 이런 문제를 해결하기 위해 몇가지 솔루션이 존재한다.

API를 통한 데이터 가져오기
-------------------------------

    다양한 변형 Model들이 존재하지만, 리포팅 DB의 목적은 데이터 가져오는 것에 의존한다.
    둘 이상의 시스템 간에 데이터를 리포트한다면 모으기 위해 호출을 여러 번 해야 한다.

이 접근 방식은 **대용량의 데이터를 필요로 하는 사용 사례의 경우** 바로 실패한다.

리포팅 시스템 내에 있는 데이터가 실제 데이터베이스에 정보와 맞지 않을 수 있으니, **필요한 데이터베이스 정보를 가져오는데 이 작업은 매우 느린 작업이 될 것이다.**

리포팅 시스템 역시 특정 방법으로 데이터를 추출하는 외부 도구에 자주 의존하는데 몇 가지 문제가 존재한다.

### 대다수의 API는 리포팅 용도로 설계된 것이 아닐수도 있다.

    어떤 서비스는 해당 질의로 검색할 수 있게 허용 할 수 있지만, 외부로 부터 공개를 하지 않을 수도 있다.
    따라서, 모든 데이터를 얻기 위해 반복적으로 개별 호출을 시도하여 해당 서비스에도 부하가 될 수 있다.

물론, 서비스에 의해 노출되는 자원에 대한 리버스 프록시 같은 장소에 데이터를 캐싱할 수 있지만, 아무도 요청 하지 않았던 자원을 요청 할 수 있어 **캐시 미스가** 발생 할 수 있다.

### 리포팅을 위한 일괄 API를 생성하기

    서비스는 일괄 API를 통해 데이터 리스트를 전달받아 해당 정보를 추출하거나 모든 데이터를 페이지 단위로 제공하는 인터페이스를 노출할 수 있다.

해당 API를 호출하면, 아직 처리되지 않았음의 코드 '202'를 되돌려주고, 호출 시스템은 자원이 생성되었음을 명시하는 201 코드를 받기 전까지 폴링할 수 있고, 응답을 받은 후 데이터를 가져올 수 있다.

하지만, 이 방법은 복잡하고 단지 리포팅 시스템을 위해 API를 만드는 것은 과잉 대응이라고 생각한다.

데이터 펌프
------------

    이전 까지는 리포팅 시스템이 데이터 베이스에 요청을 하여 끌어오는 방식을 선택하였다.
    하지만, 오히려 반대로 리포팅 시스템에 데이터를 밀어 넣는 방식은 어떤가?

아까 말했듯이, HTTP 호출로 데이터를 추출하는 데 있어 부하와 리포팅 목적으로 사용하는 API를 만드는 것은 부담이다.

역발상으로, 데이터의 소스인 **데이터베이스에 직접 접근하여 리포팅 데이터베이스로 밀어 넣는** 독립 프로그램을 가지는 것이다.

하지만, 이렇게 된다면 강한 결합성을 초래하는 데이터베이스 통합과는 완전히 일맥상통이 된다!

그럼에도 불구하고, 이 행위는 적절하게 구현만 되었다면 리포팅을 쉽게 생성하며 **결합으로 인한 단점을 크게 완화할 수 있는 주목할 만한 예외다.**

### 데이터 펌프 시작하기

    데이터 펌프를 사용하려면, 해당 서비스를 관리하는 팀이 그것을 개발하고 관리해야 한다
    Cron과 같이 단순한 명령행 프로그램이 될 수 있으며, 해당 서비스의 내부 DB와 리포팅 스키마 모두 잘 알고 있어야 한다.

펌핑 작업은 스키마 하나를 다른 것과 매핑한다(?).

데이터 펌프 관리팀이 서비스 스키마와 결합되는 문제를 줄이도록 노력한다.

추가적으로 서비스와 데이터 펌프중 하나가 배포될 때 같이 배포할 것을 가정해 버전을 함께 관리하고ㅡ 데이터 펌프를 서비스 자체 빌드의 일부로 추가해 부차 결과물로 생성할 것을 제안(??)

리포팅 스키마 자체의 결합 문제가 남아있지만 그것을 변경하기 어려운 게시된 API처럼 다루어야 한다.

#### 엔드포인트 대체

    어떤 기업은 AWS S3를 실제로 거대한 데이터 마트(데이터를 꺼내 사용자에게 제공하는 역할)로 위장하여,
    JSON 파일을 S3에 저장하기 위해 데이터 펌프를 사용하였다.

> 이 방법은 솔루션이 확장이 필요할 때까지 효과가 있었다.

이벤트 데이터 펌프
---------------------

    마이크로서비스의 코레오그래피 패턴, 기억나는가?
    한 서비스의 이벤트를 계속 주시하면서 이벤트가 발생하면 처리하는 패턴이다.
    이러한 이벤트 피드를 노출하는 마이크로서비스에 대해 리포팅 데이터베이스로 밀어 넣는 자체의 이벤트 구독자를 작성할 수 있다.

만약 데이터 베이스에서 상태가 바뀐다면, 외부 소비자에 노출된 이벤트에 바인딩하여, 중앙의 리포팅 저장소에 어떤 데이터를 보낼지 현명하게 정할 수 있다.

또한 처리된 이벤트를 저장한다면, 새로운 이벤트만 처리하여도 충분하며 이벤트 흐름의 본질적인 타임스탬프는 큰 도움이 된다.

> 하지만, 이 구조는 모든 이벤트를 처리해야한다는 단점이 있다.

백업 데이터 펌프
------------------------

    기존의 백업 솔루션을 활용하여 확장성 문제도 해결한다.

넷플릭스 많은 서비스를 위한 자료 저장소로 카산드라를 선택하였다.

카산드라 데이터를 백업하기 위한 일반적인 접근법은 데이터 파일을 복사해서 안전한 곳에 저장하는 것인데, SSTable로 잘 알려져 있는 파일들을 AWS의 S3 객체 저장소에 저장하였다.

넷플릭스는 이 모든 데이터를 리포트하는 방법으로, SSTable에 백업된 것을 작업 원본으로 사용하는 하둡을 통해 검색하였다.

> 하지만, 데이터 펌프 패턴 역시 리포팅 스키마와 결합되어 있다.

변경 비용
----------------

### 적어도 왜 동작하는지는 알아야 한다

    마이크로서비스화를 점진적인 변경의 필요성을 장려하는 많은 이유가 있지만,
    주요 요인중 하나는 우리가 만드는 가각의 수정과 필요할 경우 방향을 변경할 떄의 영향도를 이해하는 것이다.

이는 실수의 비용을 완화하지만 실수의 기회를 완전히 없애지는 못한다.
우리는 실수를 할 수 있고 할 것이므로 그것을 수용해야 한다.

### 실수의 비용을 줄이는 방법

    코드 베이스에서 코드를 나누는건 비용도 낮고, 많은 도구가 있어 일반적으로 빨리 해결할 수 있다.
    하지만, 데이터베이스를 분리하는 것은 많은 작업이 필요하고 복잡한 일이다.

많은 작업과 복잡하다는 의미는 작업이 점점 더 위험해진다는 것을 의미한다.

이런 위험을 관리하는 방법은 제안하는 디자인을 스케치하고 그 사용 사례들을 자신이 생각하는 서비스 경계를 넘어 실행할 때 어떤 일이 발생할지 예측하는 것이다.

여기에서 사용될 훌륭한 기술은 CRC 카드다.

#### CRC 카드란?

<img src='http://www.academis.eu/posts/images/crc.png'>

*팩맨의 유령을 CRC Card로 표현한 것*

    색인 카드에 클래스 이름, 그것의 책임, 누구와 협업하는지 기입한다.
    제안된 디자인을 통해 작업할 때 가각의 서비스에 대해 그것이 제공하는 기응 측면에서의 책임과 다이어그램에 지정된 협업자를 나열한다.

더 많은 사례를 통하여 이 모든 것이 적절히 들어맞는지 감을 잡을 수 있을 것이다.
