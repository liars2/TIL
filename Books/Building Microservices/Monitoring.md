모니터링
=========

모놀리식 시스템에서는 에러가 나면 한 곳만 보면 됬다. 단일 장애 지점이기 때문에 서버는 뻗지만, 어디서 문제가 있는지 한 곳만 보면 되니까 분석이 굉장히 쉽다.

하지만 마이크로서비스는 다양한 서비스를 쪼개고, 단일 장애 지점이 아닌 한 서비스가 종료되도 지속적으로 운영할 수 있는 구조이기 때문에 서버에 장애가 발생하였을 때 장애를 해결하기에 봐야할 서비스가 한 두개가 아니다. 마이크로서비스의 장애를 분석하기 좋은 방법은 여러가지가 있지만, 가장 보편적이고 가장 먼저 찾는 로그를 제공하는 것. 모니터링에 대해 설명하는 글이다.

### 로그

    로그파일은 운영 체제나 혹은 통신 소프트웨어 간의 메시지를 기록한 파일이다.

서비스 운영별 신경써야 할 모니터링 관리
---------------------------------------

### 단일 서비스, 단일 서버

    한 서버의 한 가지 서비스만 운영한다는 것은, 한가지 로그만 보면 된다.
    하지만, 이 로그도 3년이 지나면 필요없는 로그가 된다. 1년만 지나도 가치 없는 로그가 되므로..
    그래서 주기적으로 로그를 지워야 하는데, 일일히 사용자가 로그 생성 날짜를 보고 지울 필요없이 따로 지원하는 프로그램이 있다.

#### 로그 주기(週期)

    로그는 점진적으로 쌓여만 간다, 3년전 로그 덕에 디스크 공간을 다 채워지게는 냅둘 순 없을 것이다.
    그래서 로그는 일정 주기마다 지워야 하는데, logrotate등 여러가지 지원하는 프로그램이 있다.

### 단일 서비스, 다수 서버

    한 가지 서비스여도, 서버단위로 로그 파일이 생긴다.
    모든것을 모니터링하고 보고 싶어하는데 수 많은 서버들을 봐야하는가?

실환경에서 문제가 발생했을 때 문제를 찾는 행위는 수 많은 서버의 로그를 그냥 보는 것이 아닌 문제의 로그를 봐야 하는 시점이다.

호스트 레벨의 측정지표를 알아야 하는데 그러기 위해서는 모든 것을 취합(聚合)하고 세부 분석을 할 수 있어야 한다.

그렇기 위해서 호스트 그룹으로 나누어 관리하듯이 애플리케이션도 유사하게 적용하기에 충분 할 것이다.

하지만, 더욱 더 걱정되는 것은 로그파일인데, 서버가 30개라고 가정했을 때 해당 로그 파일을 얻기위해서 30개를 하나씩 로그인해서 해당 로그 파일 경로를 찾아가 로그를 다운 받는 행위를 30번 정도 반복하면 그에 따른 인력 손해가 막심할 것이다.

그래서 SSH 멀티플랙서와 같은 도구를 사용하여 로그를 볼 수 있다. (`grep 'Error' || cat foo/bar/logs/*.log`)

응답 시간 추적과 같은 작업을 하기 위해서는 다수의 서버로 작업을 할당해주는 로드밸런서도 추적 대상이 되어야 한다.

그래서, 단일 서비스를 구동하는 다수 서버는 주의해야 할 점은 아래와 같다.

1. 다수 서버의 지표를 만들기위해 모든 것을 취합하고 세부분석 후 관리하기
2. 편하게 취합하기 위해 도구를 사용하기
3. 응답 시간 추적은 로드밸런서의 모니터링

### 다수 서비스 다수 서버

    올것이 왔다, 마이크로서비스의 성질중 하나인 다수 서비스로 돌아가는 구조다.
    다수 서비스 그리고 다수의 서버로 운영한다면 설계하기도 물론 유지보수 하기도 힘든 구조이다.
    수천개의 로그 수천개의 소스코드.. 어떻게 해야할까?

위 처럼 지표를 먼저 만들어야 한다. 하지만, 조금 다른점이 있다면 애플리케이션 측정지표도 봐야한 다는 점이다.
기존에는 로그만 봤는데 로그만 보는 이유는 서비스가 하나이기 때문에 상관이 없지만 다양한 서비스가 공존하고 있다는 것은 서로 다른 애플리케이션을 사용하고 있을 수 있다는 가정이 성립된다.

그래서, 다수 서비스 다수 서버같은 구조에서는 로그부터 애플리케이션까지의 측정지표를 취합하고, 분석하는 것이다.

로그의 바다
------------

    로그, 로그, 더 많은 로그.. 끝이 없는 로그를 3000개의 서버에서 돌아가는 수 많은 마이크로서비스에서 가져온다고 가정한다면
    SSH 멀티 플렉싱을 사용하여 가져온다고 하면, 100인치 모니터여도 전부 터미널을 담을 수 없는건 물론이다. 어떻게 해야할까?

로그를 가져오기 위해 클라이언트가 직접 가져오는 것이 아닌, 역으로 클라이언트가 한곳으로 로그를 모으는 시스템이 존재한다.

### 로그를 관리하는 서비스들

#### 로그스태쉬

    많은 로그 파일을 파싱하고 추가 분석을 위해 하부 시스템에 전송하도록 도와주는 로그 서비스다.

#### 키바나

    파싱한 정보로 사람이 쉽게 눈으로 볼 수 있도록 로그를 보기 위해 만들어진 일레스틱서치 기반 시스템이다.

[_키바나 공식 홈페이지_](https://www.elastic.co/products/kibana)
[일레스틱서치](https://ko.wikipedia.org/wiki/%EC%9D%BC%EB%9E%98%EC%8A%A4%ED%8B%B1%EC%84%9C%EC%B9%98)

측정지표
--------------

지표 : 방향이나 목적, 기준 따위를 나타내는 표지.
측정 : 일정한 양을 기준으로 하여 같은 종류의 다른 양의 크기를 잼. 기계나 장치를 사용하여 재기도 한다.

    측정지표는 일정한 양을 기준으로 하여 나타내는 표지라고 생각할 수 있다. 이것이 컴퓨터에 접목시킨다면 CPU 부하 주기, 메모리 사용량, 에러 코드 반환 등으로 나타낼 수 있다.
    그럼 이 측정지표를 만들기 위해서는 어떤 양의 수치를 설정해야 하는데 어떻게 해야할까?

간단하다. 명확한 패턴이 드러날때까지 기다리고 기다려서 시스템의 행동 방식에 따라 측정값을 설정하고 측정지표를 만드는 것이다.

하지만, 한 머신에서 여러 서비스가 돌아가는 것 같은 경우에는 머신 자체에 측정지표는 쉽게 세울 수는 있지만, 머신안에 있는 서비스 종류의 측정 지표를 세우는 것은 어렵다.

이것은 구조를 추론할 수 있도록 메타데이터와 측정지표를 연결할 수 있어야 한다는 것인다.

**[그래파이트는](https://en.wikipedia.org/wiki/Graphite_(software)) 이를 쉽게 만들어주는 시스템 중 하나다**

측정지표의 시간의 경과에 따라 변화되는 상태를 이해하는 다른 혜택은 용량 계획이다.

물론 지금은 LaaS에 의해 쉽게 사용할 수 있자만. 시스템의 비용 효율성과 응답성도 높아진다.
