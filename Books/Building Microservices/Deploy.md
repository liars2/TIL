배포
==============

    최종 사용자에게 소프트웨어를 전달하는 과정을 배포라고 한다.
    모놀리식 애플리케이션의 배포는 간단하지만, 상호 의존성을 중시하는 마이크로서비스의 배포와는 전혀 다르다.

CI
---

    지속적 통합(Continuous Intergration)은 퀄리티 컨트롤을 적용하는 프로세스를 실행시키는 것이다.
    개발 관점에서 보면, 지속적으로 작성해온 코드베이스를 합쳐 서비스에 올리는 것이다.

### CI가 필요한 이유

    CI를 하지 않는다면 다음과 같은 문제 상황이 발생한다.

1. 다른사람과 동기를(서비스의 코드) 맞추지 않아, 완전히 서로 다르거나 혹은 이미 구현한 컴포넌트등 침해할 수 있음

2. 지속적으로 하지 않는다면, 릴리즈 주기가 매우 길어져 사용자들에게 서비스를 보여주지 못하는 상황이 발생

3. 배포하는데 도구 혹은 절차가 존재하지 않는다면 릴리즈 하는데도 비용과 시간이 많이 든다.

[위와 같이 혼돈의 상황을 Hell이라고 부르는걸 좋아하는 서양 문화 답게 통합의 지옥이라고 부른다.](http://c2.com/cgi/wiki?IntegrationHell)

```CI를 한다면 이런 이점을 얻을 수 있다.```

1. 코드 품질에 대한 빠른 피드백을 얻을 수 있다.

2. 산출물의 빌드를 위한 모든 코드는 버전 관리되므로 언제든지 다시 만들 수 있다.

3. CI 도구 자체의 기능에 따라 어떤 테스트를 하였는지 확인 할 수 있다.


### CI의 동작방식

    코드베이스에서 주 브런치에 Commit이 된다면, 해당 커밋에 대한 테스트와 각가지 단계를 파이프라인으로 다루어 배포를 한다.

#### 파이프라인?

    파이프라인(Pipe Line)이라는 용어는 많이 사용되는데, 개발에서의 파이프라인 혹은 단계에서의 파이프라인 등등 사용되는데,
    이 전 단계의 결과 값을 다음 작업으로 넘겨주는것을 파이프라인이라고 한다.

> Ex) 프라미스 체인도 파이프라인이다.
```
Promise(() => pseudoAsync()).then(...).then(...).then(...)
```

### 빌드 파이프 라인 동작 과정

    일반적인 빌드 파이프 라인 동작 과정은 이와 같다.

> 컴파일과 빠른 테스트(유닛 테스트) -> 느린 테스트(통합 테스트) -> UAT(사용자 인수 테스트) -> 성능 테스트 -> 실환경 배포

**서비스는 모든 다양한 환경에서 동일해야 한다.**

#### UAT 사용자 인수 테스트

    시스템이 실제 운영 환경에서 준비가 되었는지 최종적으로 확인하는 단계

사용자가 테스트를 해서 잘못된 점이나 이해가 상충되는 부분을 확인, 테스트 하는 절차이다.

### CI 도구와 CI는 다르다.

    위와 같은 도구들을 사용한다고 해서 CI를 실천한다고 할 수 있을까?
    제즈 험블의 3가지로 CI를 사용하고 있는건지 CI 도구만 사용하는 건지 알 수 있다.

##### 1. 하루에 한 번 메인 브랜치에 체크인하는가?

    여러분의 코드는 물론, 다른 사람들이 변경한 코드 또한 자주 확인하지 않는다면 통합이 더 어려워 진다.
    변경을 위해 단기 브랜치를 사용하여도 메인 브랜치에 통합해라.

##### 2. 변경을 확인할 테스트 집합이 있는가?

    테스트를 하지 않는다면 통합해서 작동하는지 구문상으로만 알 수 있으며, 시스템의 동작을 중단시키는 것 까지는 알 수 없다.
    코드가 기재한대로 동작하는지 검증하지 않는 CI는 CI가 아니다.

##### 3. 빌드가 깨졌을 때 팀이 그것을 최우선으로 하는가?

    녹색 빌드는 변경한 것이 안전하게 통합되었고, 적색 빌드는 마지막 변경이 통합되지 않았음을 의미한다.

빌드 문제의 해결과 관련 없는 추가적인 체크인을 중단해야 한다.


모놀리식 서비스는 큰 통합 서비스, 마이크로서비스는 분할 통합 서비스???
---------------------------------------------------

    기존 모놀리식 서비스는 충돌만 고려하면서 서비스를 운영만 하였으면 됬었다.
    하지만, 마이크로서비스는 모든 서비스를 고려하면서 배포해야 한다, 좋은 방법이 있을까?

몇 가지 방법이 있는데, 가장 단순한 방법은 하나로 엮는것이다.

지속적으로 통합하는 서버를 만들어서, 커밋이 있을 때 마다 해당 소스코드를 모두다 가져와 빌드 하는 것이다.

이것을 락스텝 릴리즈라고 한다.

```
Object 예제
CI_BUILD_LIST
[
    { Name: A, Source: 1, Version: 1.3 },
    { Name: B, Source: 2, Version: 1.3 },
    { Name: C, Source: 3, Version: 1.3 }
]

위에 예제의 Source가 숫자로 나타낸다고 하자, 만약에 B의 소스가 업데이트 되어 4로 됬다면 해당 빌드는 이렇게 변한다.

CI_BUILD_LIST
[
    { Name: A, Source: 1, Version: 2.4 },
    { Name: B, Source: 4, Version: 2.4 },
    { Name: C, Source: 3, Version: 2.4 }
]

이렇게 된다면, 한 서비스의 일부분만 바꿔도 모두다 빌드한다는 단점이 있다.
```

테스트할 필요가 없는 것까지 테스트하므로 실제로 필요 이상의 시간이 소요될 수 있다.

> 이것은 하나의 변경을 개발에서 실운영환경에 전달하는 속도, 즉 순환 시간에 영향을 준다.

이런 방법을 개선하기 위해, CI 빌드가 한가지의 서비스만 빌드 하도록 하면 된다.

```
Object 예제

USER-SERVICE-BUILD = { Name: USER, Source: 1, Version 0.1 }
CATALOG-SERVICE-BUILD = { Name: CATALOG, Source: 2, Version 0.3 }
Invoice-SERVICE-BUILD = { Name: INVOICE, Source: 3, Version 0.2 }

이런식으로 단일 산출물을 만들 수 있다, 그래서 앞서 말한 한 서비스의 일부분 업데이트여도

USER-SERVICE-BUILD = { Name: USER, Source: 3023, Version 4.9 }
CATALOG-SERVICE-BUILD = { Name: CATALOG, Source: 2, Version 0.3 }
Invoice-SERVICE-BUILD = { Name: INVOICE, Source: 3, Version 0.2 }

이렇게, 한 가지 서비스만 수행하고 배포할 산출물만 얻는다.
```

#### 아이를 반으로 나누거라

    우리가 원하는 필요없는 과정도 생략하고, 서로 다른 빌드를 가질 수 있어 관리하기도 편해졌다.
    근데, 그렇다면 소스 코드 저장소 혹은 이 세세한 서비스들의 관리자는 어떻게 선택할 수 있는가?
    누군가 솔로몬이 되어 이 문제를 해결해야 하는가??

간단하다! 각각 코드를 통합한 것으로 가져온 것이 아닌 하나의 코드저장소를 가지게 만들면 된다!

### 지속적 배포(Continuous Delivery)

    지속적 배포는 모든 체크인의 실환경 준비에 대한 지속적인 피드백을 얻고,
    나아가 모든 체크인을 빠짐없이 릴리즈 후보로 여기는 접근 방법이다.

CD를 완벽히 지원하는 도구는 소프트웨어의 실환경에 이르는 전체 경로를 모델링하면서 파이프라인들을 정의하고 시각화한다.

소프트웨어의 생산 경로 전체를 모델링함으로써 소프트웨어 품질의 가시성을 크게 향상시키고 개선할 주요 사안인 빌드 및 리리즈 프로세스를 한 곳에서 볼 수 있으므로 릴리즈 간 소요 시간을 크게 줄일 수 있다.

### 앞서 말한 빌드당 서비스가 만병 통치약일까?

    팀이 새로운 프로젝트, 아무것도 없는 무에서 유를 만들 때
    서비스 경계를 확정하는 동안 도메인 개념이 있을 때 까지는 서비스를 큰 부분으로 유지하는 것이 좋다.

이 확정하는 동안, 거의 혼돈의 상태로 서비스가 안팍에 있던게 매일매일 바뀌고 달라지므로, 하나의 빌드로 포함시키는 것이 좋다.

플랫폼별 산출물
-----------------

    대부분의 기술스택들은 서로 다른 확장자를 가지고 있다.
    자바에는 JAR, 루비는 GEM, 파이썬은 Egg .. 등등

하지만 마이크로서비스 관점에서는 기술 스택에 따라 산출물 자체만으로 부족할 수 있다.

자바의 JAR파일을 실행시킨다면 프로세스 매니저를 사용하나등 산출물을 배포하고 실행하기 위해 다른 소프트웨어를 설치하고 구성할 방법도 필요하다.

이러한 산출물들이 특정 기술에 스택에 한정되어 있을 때 생각해보자.

루비 gem, JAR 파일, Node.js , npm 패키지 등 전혀 다른 배포 메커니즘을 사용한다면, 그 기술을 테스트 하려는 사람 혹은 배포 관리자는 지옥을 맛 볼 것이다.

자동화는 하부 산출물의 배포 메커니즘의 차이를 감추는 데 크게 도움이 된다.

운영 체제 산출물
------------------

    특정 기술에 제한적인 산출물과 관련된 문제를 해결할 수 있는 방법은 간단하다.
    운영 체제 네이티브한(Windows MSI, Redhat Linux RPM, Ubuntu deb) 산출물을 생성하면 된다.

이렇게 운영 체제 산출물을 사용한다면, 하부 기술에 대한 것을 신경 쓸 필요 없고 해당 패키지의 도구만 사용하면 된다.

하지만, 이런 방법으로 한다면 굉장히 어려움을 겪거나 단점이 존재한다.

1. FPM으로(리눅스) 패키지리를 만드는 것은 쉽지만, MSI 및 나머지는 만들기가 까다롭다.

2. 다른 운영 체제에 배포를 할 때. 다른 운영체제에서 산출물을 관리하는 일은 부담스러운 일이다.

서버 설치하는데만 30년
----------------------

    자바 애플리케이션 배포를 위해 서버를 프로비저닝 하자고 하였을 때,
    오라클 VM을 설치하는데, 5분 머신이 프로비저닝 되는데 2~3분, JVM을 설치하는데 3분.
    그리고 드디어 우리가 원하는 소프트웨어를 설치 할 수 있다.

소프트웨어는 통계를 위한 콜렉트디, 로그를 위한 로그스태쉬, 모니터링을 위한 나기오스를 적절히 설치...

시간이 지날수록 소프트웨어 설치할 것이 많아지고, 의존성을 가진 것들을 또 프로비저닝 하자면.. 서버 설치만 하다가 끝날 것이다.

물론 퍼펫, 셰프, 앤서블, 그리고 이들의 부류는 이미 설치된 소프트웨어를 재설치하지 않겠지만, 이것을 또 확인하는 작업도 시간이 걸리므로 언제나 빠른 것은 아니다.

그리고, 해당 머신들을 가까이 두면 환경불일치(임의로 설치한 것들로 인해 구성의 차이가 발생하는 것)를 초래하여 피하고자 한다.

주문형 컴퓨팅 플랫폼을 사용하고 있다면 하루단위로 새로운 인스턴스를 계속 끄고 켤 수 있다. (주문형 컴퓨팅은 유저를 위해서 컴퓨터 자원들을 사용할 수 있게 만드는 배달모델이다)

### 기동시간 줄이기
    계속 될수록 제대로 소프트웨어가 설치 혹은 환경이 구성되어있는지 확인하는것은 지겹다
    만약 하루에도 여러 번 확인하려 한다면 빠른 피드백을 제공하는 측면에서는 실제로 문제가 될 수 있다.

소프트웨어를 설치하기 전에 모든 필수 구성 요소(Provisioning Task, OS, JVM, library) 설치 할 때 까지 제로-다운타임을 허용하지 않는다면 **실환경에 배포 시 다운타임이 늘어날 수 있다.**
이 기동시간을 줄이는 방법은 공통적으로 의존하는 것들을 주입한 **가상 머신 이미지를** 만드는 것이다.

결국에는 설치하는 시간만 들테고 소프트웨어를 찾고 설치하고 깔고.. 하는 시간이 많이 드는 작업들이 사라지기 때문에 **시간을 상당히 줄여준다.**

그래도 세상엔 완벽한 것은 없다고 몇 가지 단점이 존재한다.

#### 커스텀 이미지의 단점

1. 이미지의 생성 시간이 오래 걸릴 수 있다.
    - 배포용 바이너리 설치하는데 30분, 1시간, 1시간 30분.. 그 이상이 걸린다면 다른 배포 방법을 찾는게 더 빠를지도 모른다.

2. 생성된 이미지가 클 수 있다.
    - 로그도 넣고, 내부 DB도 넣고, 또 다른 의존성을 챙기고 만들어진 이미지가 매우 크다면.. 네트워크를 통해 쉬운일이 아닐지도 모른다.</br>그래서, 이런 단점을 보완한 컨테이너 기술이 있다.

그리고, 이것도 여러가지 플랫폼이 있기 때문에(VMWare, AWS, 베이그런트, 랙스페이스 등등..) 머신 환경 구성을 위해 사용되는 다른 도구들과 호환되지 않는다.

### 커스텀 서비스 이미지

    의존성만 커스텀 이미지로 만들라는 규칙과 규정은 없다, 그렇다면 서비스도 이미지로 만든다면 어떻게 될까?

실제 넷플릭스도 빠른 가동 시간으로 인해 자신들의 서비스를 AWS AMI로 생성하는 모델을 채택하였다.

결과적으로 따져보면 *기술 스택이 어쩌고..어떤 기술(JAR 혹은 GEM)으로 돌려야 한다.* 라는 것을 신경 쓸 필요 없이

서비스의 동작 유/무만 보면 되는 거니까 배포하는 데 초점을 둘 수 있고, 또 다른 배포 개념인 **불변 서버를** 구현하는데 좋은 방법이다

### 불변 서버

    모든 환경 구성을 소스 관리 시스템에 저장함으로써 서비스뿐만 아니라 전체 환경까지 자동적으로 복제하려 노력한다.
    그러나 우리가 배포 프로세스를 실행하고 나서 누군가 머신에서 소스 관리 시스템에 있는 것과는 별개로 변경한다면 어떻게 될까?

전에 말했던 **환경 구성 불일치**라고 알려진 문제로, 소스 관리 시스템의 코드가 실행 중인 호스트의 환경 구성에 더 이상 반영되지 않는 상태를 말한다.

#### 문제를 피하는 방법

간단하다, **건들지 않으면 된다.** 아주 아주 작은 코드 한 줄이여도 **새로운 머신을 생성하기 위해서는 빌드 파이프라인을 통해야 한다.**

이미지 기반의 배포 방식을 사용하지 않더라도 이 패턴을 구현할 수 있지만, 산출물이든 다른 서비스를 이와 같이 사용하는 방식의 논리적 확장이다.</br>
*이미지 기반 배포방식 X 이 패턴을 사용하는 것은, 산출물이든 다른 서비스를 이와 같이 행동하는 똑같은 방식의 논리적 확장이다.*

이 패턴은 하나의 변경을 개발에서 실운영환경에 전달하는 속도인 **순환 시간**에 대해 동일한 유의 사항이 적용된다.

그리고, 머신에 사용되는 모든 데이터가 다른 곳에도 저장되는 것을 보장해야한다.

> 정말 엄청 복잡한 방식이지만, 그에 따른 직관적인 배포와 추론하기 쉬운 환경을 이끌어 낸다.

환경
--------

    전에 말했듯이, 서비스가 배포 되기 전에는 CD의 파이프라인을 완전히 통과 해야한다.
    그러면 느린 테스트, UAT, 성능, 실운영 환경들을 고려해야 할 것이다!

각각의 환경마다 적어도 분리되고 구별되는 환경 구성과 호스트가 있지만 더 다양할 것이다.

실운영 환경 테스트에서는 분산된 서버로 구성되있을 수도 있지만, 실운영은 하나의 서버로만 동작 할 수 있다!

그렇게 되면 환경의 차이가 발생하고, 몇 가지 문제를 불러올 수 있다.

*문제가 필자가 겪었던 입장으로 적혀져 있어, 후에 추상화해서 추가할 예정*


서비스 환경 구성
----------------

    서비스는 몇 가지 환경 구성을 필요로 한다, 이상적으로 환경 구성은 작아야 하며,
    '데이터 베이스에 접속 하기 위해 어떤 계정을 사용해야 하는가?' 와 같이 변경해야 하는 제한된 기능이 될 것이다.

환경 구성이 본질적인 서비스 행위를 더 많이 침해할수록 환경 구성은 환경마다 더 달라지고 특정 환경에서 발생되는 문제도 더 많아진다. 정말 끔찍한 일이다.

> 그러므로, 환경 구성은 전적으로 최소화되어야 한다.

서비스의 환경마다 바뀌어야 할 몇 가지 환경 구성을 가지고 있다면 배포 프로세스의 일부로서 어떻게 다루어야 할까?

### 하나의 환경당 산출물을 빌드한 후, 환경 구성을 산출물에 포함시키는 방법

    환경 구성이 빌드되어 산출물에 포함되므로 배포하기만 하면 모든 것이 잘 동작해야 한다.

하지만, 이것은 문제가 될 수 있다

산출물들을 빌드하기 위해서는 또 추가적인 시간이 소요된다.

빌드 시간에 어떤 환경이 존재해야하는지 알아야하고, 민감한 환경 구성 데이터(비밀번호, 토큰 등등..)을 어떻게 다룰 것인지.

### 환경마다 가지고 있는 환경 구성들
    더 나은 방법은 단일 산출물을 생성하여 환경 구성을 분리해서 관리하는 것이다.

각 환경에 속성 파일 또는 설치 프로세스에 전달될 다른 매개 변수와 같은 것이 될 수있다.

EX) TEST환경에는 TEST 전용 DB의 정보, 실운영 환경에서는 항상 복제하고 관리하는 DB의 정보

머신당 얼마나 많은 서비스가 있어야 하는가?
---------------------------------------

    옛날에는 오직 스케일 인, 아웃과 같이 물리적인 단위에서만 고려하여 서비스 운영 하였지만
    가상화 시대로 들어온 지금은 운영 체제를 실행하는 단일 호스트와 하부의 물리적인 인프라스트럭처의 매핑은 매우 다양하다.

### 1 HOST, N Service

    하나의 호스트에서 한 서버에(호스트) 하나 또는 더 많은 서비스를 돌리는 가상화를 사용하면 많은 이점이 존재한다.

1. 호스트 관리 관점에서의 단순함
    - 애플리케이션 동작에 필요한 자원을 한 팀이 담당하고, 소프트웨어를 다른 한 팀이 담당한다면 애플리케이션 동작에 필요한 자원을 관리하는 팀의 작업량은 대체로 관리해야 하는 호스트의 수와 연관된다.

2. 비용감소
    - 한 서버에 여러 서비스를 운영할 때, 서비스의 크기만큼 가상 서버의 필요한 리소스를 제한 할 수 있어 효과적인 비용절감을 할 수 있다.

하지만, 이렇게 좋아보이는 가상화 호스트도 이런 문제도 존재한다.

1. 모니터링에 어려움
    - 여러 서비스가 있을 때, CPU 같은 상태를 추적할 때 독립적으로 사용한 CPU 상태를 추적해야할까? 아니면 호스트에 있는 모든 서비스를??
    - 또 한 서비스가 많은 부하가 생긴다면 시스템의 다른 자원을 차지해 가용할 수 있는 리소스가 줄어들게 된다

2. 의존성
    - 호스트를 준비하기 위해 어떤 구성 관리 도구를 사용할 때, 각 서비스에 다르거나 혹은 모순될 수 있는 의존성이 있다면 어떻게 해결해야 할까?
        - 독립적인 릴리즈를 포기하고 호스트에 들어갈 다수의 서비스들을 묶어서 호스트에 배포하는 것은 마이크로서비스의 원칙을 깨트리는 것이다.

호스트당 다수의 서비스 모델을 적용한다면 각 서비스가 독립적으로 배포되어야 하는 아이디어를 고수하도록 노력하라

3. 자율성
    - A서비스를 개발하는 갑 팀과, B서비스를 개발하는 을 팀들이 한 호스트 안에 서비스가 공존한다고 하자. 그러면 그 호스트의 구성은 누가 해야할까????
    - 당연히 갑 팀에서 하게 될것이며, 이는 서비스를 배포하기 위해 호스트 구성에 조율이 필요하다는 것을 의미한다.

4. 배포 산출물의 방식 제한
    - 모든 서비스가 단일 산출물로 묶지 않는다면, 불변 서버가 불가능 하듯이 이미지 기반의 배포도 불가하다.

> 한 호스트가 다수의 서비스를 가지는 것은 서비스를 최대로 확장하기 위해 복잡한 노력이 필요함을 의미한다.

#### 주문형 컴퓨팅 플랫폼
    호스트가 회사들은, 물리적인 서버를 사거나 대여받는 것 밖에 방법이 없었다.
    하지만, 오늘날 주문형 컴퓨팅 플랫폼은 컴퓨팅 자원의 비용알 대폭 낮추었고 가상화 기술의 향상은 조직 내 호스팅된 인프라스트럭처에 대해 많은 유연성을 제공했다

ex) google cloud, AWS.

### 애플리케이션 컨테이너

분리된 서비스나 애플리케이션이 하나의 호스트 상의 에플리케이션 컨테이너에 머무르는 모델에 대해서도 잘 알고 있을 것이다.
애플리케이션 컨테이너 안에 서비스가 머무르는 아이디어는 인스턴스들의 그룹화나 모니터링 도구 등을 다루는 클러스터링 지원처럼 관리성이 향상된 측면에서 많은 혜택을 가져다준다.

장점
1. 언어 런타임의 부하를 줄이는 면에서도 이점이 있음.
    - 서비스 중 하나가 부하가 걸린다면, 머신 하나만 부하가 걸리므로 이점이 있다.

단점
1. 기술 선택 제한
2. 컨테이너 대부분은 공유 인메모리 세션 상태를 지원하는 클러스터를 관리할 능력을 과장한다
    - 이 기능의 문제로 서비스 확장할 때 어떤 경우에도 그 기능을 확실히 회피하길 원하며, 통합된 모니터링을 고려한다고 해도 컨테이너가 제공하는 모니터링 기능만으로는 충분하지 않다.
    기능 대부분은 기동 시간이 느려 개발자 피드백 사이클에 영향을 준다.
    - JVM과 같은 플랫폼 상에서 애플리에키션의 수명주기를 적절히 관리하려는 시도는 문제가 많고 JVM을 재시작하는 것보다 복잡할 수 있다.
    - 애플리케이션들이 같은 프로세스를 공유하므로 리소스와 스레드를 분석하는 것 또한 매우 복잡하다.
    - 특정 기술의 컨테이너로부터 이점을 얻더라도, 상용이라 비용 문제 외에도 그 자체로 자원에 대한 추가 부담이 있다.
    - 애플리케이션 컨테이너 방법은 더 이상 감당할 수 없는 자원 부족을 최적화하기 위한 시도다.

### 호스트당 단일 서비스
    말 그대로, 호스트 하나 서비스 하나 구조다.
    이렇게 된다면 우리가 고려하던 호스트당 N 서비스 구조에 대한 단점을 극복 할 수 있다.

호스트당 N 서비스 모델의 부작용을 회피(모니터링 어려움, 기술 선택 제한등..)하여 잠재적으로 단일 장애 지점(시스템이 동작하지 않으면, 전체 시스템이 종료 하는 것)을 줄인다.

특정 서비스를 다른 서비스와 독립적으로 확장할 수 있고(기술 선택의 자유), 보안 문제와 관련해서 해당 서비스와 호스트만 집중할 수 있으므로 더 쉽게 처리할 수 있다.

마이크로서비스 아키텍쳐를 적용하는데 있어 수많은 복잡성을 추가해왔고, 마지막으로 하고 싶은 것은 더 많은 복잡성을 초래하는 원인을 찾아내는 것이다.

호스트당 단일 서비스는 복잡성을 낮출 수 있으며, 추론하기 용이하다(어떤 서비스가 있는지, 서비스가 무엇을 하는지)

증가된 호스트 숫자가 잠재적인 단점이 된다, 관리해야 할 더 많은 서버가 존재하며, 개별 실해되는 더 많은 호스트로 비용 영향도 있지만, 마이크로서비스 아키텍쳐를 위해 선호하는 모델이다.

### Platform as a Service

    서비스를 개발 할 수있는 개발환경과 그 환경을 이용할 수 있는 프로그램을 개발하는 API까지 제공하는 형태

PaaS(_Platform as a Service_)은 단일 호스트보다 더 높은 수준의 추상화 대상에서 작업한다.

대부분의 기술별 산출물(JAR, GEM)을 수용하고 자동적으로 그 산출물을 프로비저닝하고 실행하는 것을 필요로 한다.

비록 일반적인 방법으로는 서비스가 실행되는 노드들에 대해 일부 통제를 하고 나머지는 PaaS가 맡더라도, 일부 PaaS는 대신하여 투명하게 시스템을 확장하고 축소하려 시도할 것이다.

PaaS의 감이 제대로 안잡힌다면, 이 한마디로 끝낼 수 있다.

> **헤로쿠가(Heroku) PaaS에서는 현재 선두주자다.**

헤로쿠는 서비스 실행, 데이터베이스 지원, 자체 호스팅까지 지원하는 것은 PaaS의 좋은 예로 들 수 있다.

#### PaaS 단점

정말 잘 작동하는 솔루션이면 잘 작동하지만, 제대로 작동하지 않는 경우에는 문제를 고치기 위해 내부를 살펴보는 것은 꽤 어려운 일이 된다.
</br>_(시스템을 확장하고 축소하려고 시도하려고 하기 때문에)_

이것은 결정해야 할 타협점 중의 일부다.

PaaS 솔루션이 더 영리해지려 할수록 더 많이 잘못될 수 있다.

[좋은 PaaS 솔루션은 대신해서 많은 것을 해주기 때문에](https://blog.heroku.com/heroku-autoscaling) 많은 변경은 부분으로 인해 늘어난 오버헤드를 처리하는 훌륭한 방법이 될 수 있다.

자동화
----------

    어찌됬든, 위와 같은 요구사항과 대처할 수 있는 방법은 자동화로 귀결된다.
    머신수가 적다면 수작업으로 관리하고, 모니터링하여 대처할 수 있지만 머신수가 점진적으로 늘어난다면 이것도 한계가 존재 할 것이다.

호스트 수를 적게 유지하더라도 많은 서비스가 존재할 수 있다. 이것은 처리해야 할 배포, 모니터링할 서비스, 수집해야 할 로그가 아주 많다는 것을 의미한다.

##### 자동화의 장점

1. 서비스의 관리가 용이해 진다.
    - 호스트당 단일 서비스로 구축 한다면, 관리하기 힘들다는 부담이 증가하지만 **이 이야기는 모든것을 수작업으로 한다고 하였을 때 적용되는 이야기다.**
    - 호스트의 통제와 서비스의 배포가 자동화한다면 호스트의 증가가 작업량을 선형적 증가가 된다는 이유가 되지는 못한다.

2. 개발자가 여전히 생산성을 유지하게 만들 수 있는 방법이다.
    - 서버수가 두 배로 세 배로 증가하더라도, 생산성을 유지 할 수 있다.
    - 각 각의 개발자마다 담당하는 서비스(셀프 서비스)가 존재한다면, 개별 서비스 혹은 서비스 그룹을 셀프 프로비저닝할 수 있도록 능력을 주는 것은 편하게 만드는 비결히다.
    - 조기에 문제를 발견할 수 있도록 실환경에 서비스를 배포하는 데 사용한 것과 똑같은 도구 체인을 사용해야 한다.

##### 자동화 기술중 필수적으로 있어야 할 기능들

1. 가상 머신을 시작하거나 종료시킬 수 있는 한 줄의 코드를 작성할 수 있는가?
2. 개발한 소프트웨어를 자동으로 배포할 수 있는가?
3. 수동적인 개입 없이 데이터베이스의 변경을 배포할 수 있는가?

> 자동화 문화를 수용하는 것은 마이크로서비스 아키텍처의 복잡성을 억제하는 핵심이다.

### 점진적으로 나타나는 자동화의 위력

    자동화의 영향력을 보여주는 사례중 2가지가 나뉘는데, REA(RealEstate.com.au)와 Gilt의 경험을 예로 들겠다.

두 가지의 서비스들은 마이크로서비스로 변환하는 과정에서 2개의 마이크로서비스만 실환경에 옮길 수 있었다, 그 다음 3개월 동안 10~15개의 서비스가 비슷한 방식으로 가동되었고

**18 개월 후에는 60~70개의 마이크로서비스로 변환했다**

Gilt도 마찬가지로, 1년 후 10개, 그 다음 해에는 100개 이상, 2년 뒤 450개의 서비스가 실행되었다.

> 이 경우를 봐서 알 수 있는 점은, 자동화 자체의 구현은 처음에는 힘들더라도 후에 서비스 구축은 점진적으로 발전 할 수 있다.

Physical to Logical Machine
-------------------

    많은 수의 호스트를 관리하는 데 사용할 수 있는 핵심적 수단 중 하나는 기존의 물리 머신을 더 작은 부분으로 묶는 방법을 찾는 것이다.
    VMWare나 AWS와 같은 전통적인 가상화는 호스트관리의 부담을 줄이는 데 있어 엄청난 혜택을 가져다주었다.

### 전통적 가상화

    호스트당 물리적인 서버가 필요하다면 당연히 비용이 많이 들 것이다.
    이처럼 운영한다면 호스트당 다수의 서비스 모델이 가장 적합할 것이다.

호스트당 다수의 서비스 모델을 공존하는 것은 제약이 있음에도 불구하고 가상화와 같은 것을 이용하는데, 물리적인 서버를 다른 일을 수행할 수 있는 호스트로 분리 할 수 있기 때문이다.

그래서 호스트당 하나의 서비스가 필요하다면 역으로 생각하여 물리적인 인프라스트럭처를 더욱 작고 작은 조각으로 나눌수는 없을까??

    VM 수를 쪼개는것은 공짜가 아니다, 물리머신이 서랍장이라면 칸막이로 정리를 한다고 공간을 많이 쓸 수 있다는 것이 아닌 그 칸막이 자체에도 공간을 소비하여 가용할 수 있는 공간이 더 적어진다!

    가상화의 세계에서는 위의 칸막이 같은 오버헤드가 발생하는데 부하가 어디에서 오는지를 간단히 설명하겠다.

물리적 인프라스트럭쳐 위에는 호스트 운영체제가 있고 이 운영체제 위에서는 하이퍼바이저로 불리는 것을 실행하는데, CPYU나 메모리 같은 가상 호스트로부터 물리적인 자원을 호스트로 매핑하고, 가상 머신을 조작하도록 통제 계층과 같은 역할을 한다.

하지만, 서랍장에 있는 칸막이 자체도 공간이 소비된다고 표현했는데. 머신에서 돌아가는 하이퍼바이저도 자신의 작업을 위해 자원을 확보해야하지 않겠는가? 그래서 다른곳에 사용할 수 있는 자원들을 결국 하이퍼바이저가 차지하게 된다.

실제로 물리적인 머신을 작은 부분으로 나누는 데 있어 수확 체감이(수확량의 증가가 노동력의 증가를 따라가지 못하는 현상) 발생함을 의미하며 하이퍼바이저의 오버헤드로 더 많은 리소스가 비례하여 생겨난다.

하지만, Bare Computing Model 같은 경우 각 VM의 커널이 필요없이 각자의 컨테이너에서 돌아가게 되는데 현대에는 이것을 이용한 여러가지 방법이 있다.

#### 베이그런트

베이그런트는 유용한 배포 플랫폼으로, 실환경보다는 개발과 테스트용으로 상요된다.
랩톱에 가상의 클라우드를 제공하며, 내부적으로 표준 가상화 시스템을 사용한다. (일반적으로 Virtual Box 사용)
베이그런트는 VM들이 서로 어떻게 네트워킹하느지와 VM이 어떤 이미지를 기반으로 해야하는지 드응ㄹ 나타내는 텍스트 파일을 통해 VM 집합을 정의한다.

##### 베이그런트의 이점

1. 로컬 머신 상에 실환경과 유사한 환경을 쉽게 생성할 수 있음
2. 다수의 VM을 한 번에 실행 시킬 수 있음
3. 장애 모드를 테스트하기 위해 개별적으로 정지시킬 수 있다.
4. VM을 로컬 디렉터리에 매핑해서 변경하고, 변경된 것을 즉시 확인할 수 있다.

> AWS를 사용하는 주문형 클라우드 플랫폼을 사용하는 팀조차도 베이그런트를 사용해서 얻는 빠른 전환은 개발팀에 아주 큰 혜택이 될 수 있다.

##### 베이그런트 단점
1. 평범한 개발용 머신에 많은 VM을 실행하는 것이 부담이 될 수 있다.

VM당 서비스 하나만 수행한다면, 전체 시스템을 로컬 머신에 주입할 수 없을지도 모르며 결과적으로 작업을 관리할 수 있도록 일부 의존성을 스텁화해야 할 필요가 있으며, 개발과 테스트의 사용성이 좋은 상태를 유지하도록 처리해야 할 부가적인 일이 될 수 있다.

#### 리눅스 컨테이너

    분리된 가상의 호스트를 구분하고 통제하기 위해 하이퍼바이저 대신 다른 프로세스들을 위해
    분리된 프로세스 공간을 생성하는 리눅스 컨테이너를 사용하는 것이다.

이 컨테이너 형식으로 동작한다면 하이퍼바이저가 필요 없고, 컨테이너가 각자의 운영체제가 있더라도 해당 운영체제의 커널을 사용하는 것이 아닌 동일한 커널(머신 커널)을 공유해야 한다.
이 뜻은 운영체제가 우분투를 실행시키고, 컨테이너가 CentOS를 실행시킬 수 있다!

##### 리눅스 컨테이너의 이점

1. 리눅스 컨테이너는 무거운 가상화 머신보다 프로비저닝이 훨씬 빠르다.
    - VMWare는 수십분이 걸릴 수도 있지만, 컨테이너는 몇 초 만에 시작할 수 있다.

2. 리소스 할당면에서도 세세한 통제가 가능하다.
    - 하부의 하드웨어를 최대한 활용하기 위해 미세 설정을 쉽게 할 수 있도록 만들어준다.

3. 더 많은 서비스를 할 수 있다.
    - 컨테이너의 경량성 덕분에 VM보다 더 많은 컨테이너를 실행시킬 수 있어, 컨테이너당 하나의 서비스를 배포함으로써 일정 수준의 격리할 수 있다.
    - VM당 하나의 서비스를 가질 때 보다 훨씬 더 비용 효율이 좋을 것이다.

4. 무거운 가상화와도 어울릴 수 있다.

##### 리눅스 컨테이너의 단점

1. 각각의 컨테이너의 연결 구조
    - 수많은 서비스가 한 호스트에서 컨테이너로 구성되어있다고 하였을 때, 외부에서 내부의 한 서비스에 접근할 때 라우팅할 방법을 찾아야 한다.
    - 컨테이너를 직접 노출하기 위해, IPTable을 이용해 포트 포워딩을 한다면 많은 시간이 걸릴 것이다.
    - 이 컨테이너들이 서로 완전히 고립될 수는 없다는 것을 알아야만 한다.

한 컨테이너의 프로세스가 다른 컨테이너 또는 하부의 호스트를 망가뜨리는 상호작용하는 많은 방법이 문서화되었고 알려져있다.
이런 문제들의 일부는 의도된 것도 있지만 일부는 해결 중인 버그에 의한 것이다.

어느 쪽이더라도 실행하는 코드를 신뢰하지 않는다면 컨테이너 안에서 실행하면서 안전하리라는 기대는 하지 말라.
그런 종류의 격리를 원한다면 가상 머신의 사용을 고려할 필요가 있다.


#### 도커

[도커의 대한 내용은 많아 이 링크에서 찾아보시길 바랍니다.](https://github.com/liars2/TIL/blob/master/Books/Building%20Microservices/Docker.md)

배포 인터페이스
---------------

    어떤 기술이던, 어떤 서비스이던 배포하는데는 일관된 인터페이스를 유지해야한다.
    개발용 환경 -> 실제 운영 환경 까지 배포하는 것도 유사한 배포 메커니즘을 유지하기 원하는데

왜냐하면, 배포 프로세스가 완전히 다르기 때문에 실환경에서 문제를 발견하는 것이다!

여러가지 배포 기법중에 가장 쉽고, 일관성이 있는 배포 방법은 매개 변수 전달이 가능한 한 줄의 명령행 호출이다.

이런 한 줄의 매개 변수가 포함된 배포 방법은 여러가지만 있지만(쉘 스크립트, 배치 파일..), 대표적으로 패브릭이 있다.

### 패브릭
[패브릭 공식 홈페이지](http://www.fabfile.org/)

    패브릭은 필요한 작업들을 미리 정의하여, 매개 변수를 사용하여 동작하는 파이썬 라이브러리중 하나인데
    이 것을 사용한다면, 쉽게 배포 프로세스를 정의 할 수 있다.

##### pseudo code

```
def update_name_file(server_path='localhost:9000', name='fabric'):
    print('hello %s!' % (name))
    conenction(server_path)
    ...
```

To deploy name file via fabric
```
fab update_name_file server_path:192.168.0.1 name:Simon
```

**이런식으로 일관성 있도록 배포가 가능하다!**
